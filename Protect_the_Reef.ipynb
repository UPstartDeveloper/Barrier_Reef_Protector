{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Starter Code from Kaggle Notebook\nThis is just being stored here for historical reasons. Will remove later. It said this:\n\n```\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport sys\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, RUN THIS (by clicking run or pressing Shift+Enter) to list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n```","metadata":{"id":"BTIQPCjxcDVI"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"5wuAfvt8gvy8"}},{"cell_type":"code","source":"import os, sys\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf","metadata":{"id":"X8NJMKgqbfve","execution":{"iopub.status.busy":"2021-12-11T20:17:08.034354Z","iopub.execute_input":"2021-12-11T20:17:08.034663Z","iopub.status.idle":"2021-12-11T20:17:08.910470Z","shell.execute_reply.started":"2021-12-11T20:17:08.034631Z","shell.execute_reply":"2021-12-11T20:17:08.909550Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Double-check Versions","metadata":{"id":"ja73-dtbcPaJ"}},{"cell_type":"code","source":"print(sys.version)  # Python version\nprint(tf.__version__) # on Kaggle, this will be 2.6","metadata":{"id":"dMvucPqKcCiC","outputId":"10c2d0de-1110-425f-b190-05942ed89964","execution":{"iopub.status.busy":"2021-12-11T20:17:12.930063Z","iopub.execute_input":"2021-12-11T20:17:12.930734Z","iopub.status.idle":"2021-12-11T20:17:12.936534Z","shell.execute_reply.started":"2021-12-11T20:17:12.930690Z","shell.execute_reply":"2021-12-11T20:17:12.935542Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis\n\n*Abbreviations*:     \n- COTS = \"Crown-of-thorns starfish\"\n\nNote: to locate where the dataset is located (on this Kaggle kernel) - I clicked on the \"copy\" button icon next to the dataset folder icon in the \"Data\" tab.","metadata":{"id":"xgRbIFh0g3h0"}},{"cell_type":"code","source":"data_path = '../input/tensorflow-great-barrier-reef'\ndf = pd.read_csv(f\"{data_path}/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:17:14.954277Z","iopub.execute_input":"2021-12-11T20:17:14.955223Z","iopub.status.idle":"2021-12-11T20:17:15.018464Z","shell.execute_reply.started":"2021-12-11T20:17:14.955167Z","shell.execute_reply":"2021-12-11T20:17:15.017577Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:17:16.224557Z","iopub.execute_input":"2021-12-11T20:17:16.225075Z","iopub.status.idle":"2021-12-11T20:17:16.323868Z","shell.execute_reply.started":"2021-12-11T20:17:16.225023Z","shell.execute_reply":"2021-12-11T20:17:16.323027Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### How to Be an Observant Surveyor\n\nMy goal in this analysis is to build an object-detection system that can scale up the efforts of manual surveyors in the Great Barrier Reef. With that in mind... what makes a human surveyor great at spotting COTS in the first place?","metadata":{"id":"AkMbPlRLg7nT"}},{"cell_type":"markdown","source":"**Question 1**: Do the COTS tend to lump close together?\n\n*Part 1:* On average, how many COTS are seen together in a single video frame?\nTo do this, let's start by first adding a column with the counts of COTS seen in each particular frame:","metadata":{"id":"FW8-Q0t6hgxt"}},{"cell_type":"code","source":"type(df['annotations'][43])  # although the data type visually looks like a list, the CSV is all text","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:17:18.548198Z","iopub.execute_input":"2021-12-11T20:17:18.548557Z","iopub.status.idle":"2021-12-11T20:17:18.559033Z","shell.execute_reply.started":"2021-12-11T20:17:18.548520Z","shell.execute_reply":"2021-12-11T20:17:18.558199Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"We know there may be multiple COTS spotted in a single frame, so let's count up each that is spotted in a new column. We'll using the `{` to know how many COTS are in each: ","metadata":{}},{"cell_type":"code","source":"count_func = lambda string: string.count('{')\nspotted = df['annotations'].apply(count_func)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:17:20.460089Z","iopub.execute_input":"2021-12-11T20:17:20.460887Z","iopub.status.idle":"2021-12-11T20:17:20.484374Z","shell.execute_reply.started":"2021-12-11T20:17:20.460839Z","shell.execute_reply":"2021-12-11T20:17:20.483272Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = df.assign(starfish_spotted=spotted)\ndf.head()","metadata":{"id":"NABW28cMhzMk","execution":{"iopub.status.busy":"2021-12-11T20:17:21.482134Z","iopub.execute_input":"2021-12-11T20:17:21.482890Z","iopub.status.idle":"2021-12-11T20:17:21.497533Z","shell.execute_reply.started":"2021-12-11T20:17:21.482845Z","shell.execute_reply":"2021-12-11T20:17:21.496851Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Cool beans! Now we can calculate the average of COTS spotted in a given frame:","metadata":{}},{"cell_type":"code","source":"mean_starfish_spotted_in_a_frame = round(df[\"starfish_spotted\"].mean(), 4)\nprint(f\"On average, {mean_starfish_spotted_in_a_frame} COTS are seen together in a single video frame.\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:17:23.100027Z","iopub.execute_input":"2021-12-11T20:17:23.100484Z","iopub.status.idle":"2021-12-11T20:17:23.105835Z","shell.execute_reply.started":"2021-12-11T20:17:23.100451Z","shell.execute_reply":"2021-12-11T20:17:23.105026Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Wowza, that seems very low. Let's also visualize the distribution of the `starfish_spotted` column using a histogram and PDF:","metadata":{}},{"cell_type":"code","source":"def plot_histogram_from_df(df, column, title, x_axis, y_axis):\n    \"\"\"\n    Plots the PDF of a column in a given DataFrame, using Matplotlib.\n    \n    Credit for the equation used for plotting the PDF goes to the NumPy documentation:\n        https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n    \n    Args:\n        df(pandas.DataFrame)\n        column(str): name of the column being plotted\n        title(str), x_axis(str), y_axis(str): will be added to the plot\n        \n    Returns: None\n    \"\"\"\n    # A: calculate the mean and std dev of the column\n    mu, sigma = df[column].mean(), df[column].std()\n    # B: init the histogram\n    bin_edges, bins_probabilites, ignored = plt.hist(df[column], density=True)\n    # C: plot the PDF \n    plt.plot(bins_probabilites, 1/(sigma * np.sqrt(2 * np.pi)) *\n               np.exp(-(bins_probabilites - mu)**2 / (2 * sigma**2)),\n             linewidth=2, color='r')\n    # D: make the plot more presentable\n    plt.title(title)\n    plt.xlabel(x_axis)\n    plt.ylabel(y_axis)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:41:41.692866Z","iopub.execute_input":"2021-12-11T20:41:41.693144Z","iopub.status.idle":"2021-12-11T20:41:41.703361Z","shell.execute_reply.started":"2021-12-11T20:41:41.693113Z","shell.execute_reply":"2021-12-11T20:41:41.702389Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"plot_histogram_from_df(df, 'starfish_spotted', \"PDF of COTS Spotted in Video Frames\", \"No. of COTS\", \"Probability\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:41:42.221812Z","iopub.execute_input":"2021-12-11T20:41:42.222258Z","iopub.status.idle":"2021-12-11T20:41:42.475454Z","shell.execute_reply.started":"2021-12-11T20:41:42.222225Z","shell.execute_reply":"2021-12-11T20:41:42.474542Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"One takeaway on this: the distribution of COTS per video frame is heavily skewed, and the majority of them have none at all. This reinforces the idea that we'll want to weigh the `recall` highly in evaluating the eventual model we build, so we can detect the relatively low number of COTS that exist per image.","metadata":{}},{"cell_type":"markdown","source":"*Part 2:* On average, how many video frames do we go without seeing any COTS in the provided videos?\n\nWith this question I am trying to get another measurement of how closely the groups of COTS are to one another. The approach which I'll take here is to gather a distribution of the numbers of frames that happen sequentially in the training data, in which there are zero COTS spotted.\n\nNote that one limitation of this approach is that certain frames might be of the same location on the Great Barrier Reef (since we don't know if the camera-person is always moving). Regardless, I think we'll go ahead with this approach anyway, since I believe it's reasonable to assume the camera is moving for most of the time in the giving videos; therefore, the amount of frames in between the time we spot any COTS is like a \"proxy\" for how close they are together.","metadata":{"id":"nO2Vr_fAhzk7"}},{"cell_type":"code","source":"def zero_sequence_lengths(a):\n    \"\"\"Compute the lengths of the sequences of consecutive zeros in an array.\n    \n    This is a modification of code by Warren Weckesser, originally posted on Stack Overflow:\n    https://stackoverflow.com/questions/24885092/finding-the-consecutive-zeros-in-a-numpy-array\n    \n    Example:\n        >>> a = np.array([[1, 2, 3, 0, 0, 0, 0, 0, 0, 4, 5, 6, 0, 0, 0, 0, 9, 8, 7, 0, 10, 11]])\n        >>> zero_sequence_lengths(a)\n            array([6, 4, 1])\n            \n    Args:\n        a(array-like object): 1-dimensional. Can have positive or negative numbers.\n        \n    Returns: 1D array-like object.\n    \"\"\"\n    # A: Create an array that is 1 where a is 0, and pad each end with an extra 0\n    is_zero = np.concatenate(([0], np.equal(a, 0).view(np.int8), [0]))\n    # B: Zero out any of the\"in between\" 1's - only 1's at edges remain\n    ones_at_edges = np.abs(np.diff(is_zero))\n    # C: Get the indices of all the remaining 1's (the starts and ends)\n    sequences = np.where(ones_at_edges == 1)[0].reshape(-1, 2)\n    # D: Compute a 1D array with just the lengths of these sequences\n    return np.squeeze(np.diff(sequences, axis=1))","metadata":{"id":"imZE_hTuh-ji","execution":{"iopub.status.busy":"2021-12-11T20:33:01.155294Z","iopub.execute_input":"2021-12-11T20:33:01.156192Z","iopub.status.idle":"2021-12-11T20:33:01.163729Z","shell.execute_reply.started":"2021-12-11T20:33:01.156134Z","shell.execute_reply":"2021-12-11T20:33:01.162699Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"I will define an \"empty frame\" as one having no COTS, and use that to make the variable names more brief:","metadata":{}},{"cell_type":"code","source":"# Compute the lengths of these consecutive frames with zero COTS\nconsecutive_empty_frames = zero_sequence_lengths(a)\n# print the mean\navg_empty = round(consecutive_empty_frames.mean(), 1)\nprint(f\"There is average of {avg_empty} 'empty' frames between the ones that do have COTS.\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:40:23.959495Z","iopub.execute_input":"2021-12-11T20:40:23.960311Z","iopub.status.idle":"2021-12-11T20:40:23.966246Z","shell.execute_reply.started":"2021-12-11T20:40:23.960277Z","shell.execute_reply":"2021-12-11T20:40:23.965270Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"So there's our answer! Out of curiosity, let's make a PDF from the distribution of these lengths:","metadata":{}},{"cell_type":"code","source":"def plot_histogram_from_arr(array, title, x_axis, y_axis):\n    \"\"\"\n    Plots the PDF of a column in a given DataFrame, using Matplotlib.\n    \n    Credit for the equation used for plotting the PDF goes to the NumPy documentation:\n        https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n    \n    Args:\n        array(array-like object): 1-dimensional, has numerical values\n        title(str), x_axis(str), y_axis(str): will be added to the plot\n        \n    Returns: None\n    \"\"\"\n    # A: calculate the mean and std dev of the column\n    mu, sigma = array.mean(), array.std()\n    # B: init the histogram\n    bin_edges, bins_probabilites, ignored = plt.hist(array, density=True)\n    # C: plot the PDF \n    plt.plot(bins_probabilites, 1/(sigma * np.sqrt(2 * np.pi)) *\n               np.exp(-(bins_probabilites - mu)**2 / (2 * sigma**2)),\n             linewidth=2, color='r')\n    # D: make the plot more presentable\n    plt.title(title)\n    plt.xlabel(x_axis)\n    plt.ylabel(y_axis)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:47:51.431604Z","iopub.execute_input":"2021-12-11T20:47:51.431875Z","iopub.status.idle":"2021-12-11T20:47:51.439188Z","shell.execute_reply.started":"2021-12-11T20:47:51.431844Z","shell.execute_reply":"2021-12-11T20:47:51.438524Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"plot_histogram_from_arr(consecutive_empty_frames, \"PDF of Empty Video Frames\", \"No. of Frames\", \"Probability\")","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:47:51.632705Z","iopub.execute_input":"2021-12-11T20:47:51.633002Z","iopub.status.idle":"2021-12-11T20:47:51.890394Z","shell.execute_reply.started":"2021-12-11T20:47:51.632969Z","shell.execute_reply":"2021-12-11T20:47:51.889373Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"Hmm... interestingly enough, there's only 3 unqiue values in this distribution, and they are not  very high.","metadata":{}},{"cell_type":"code","source":"np.unique(consecutive_empty_frames)  ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:47:36.522697Z","iopub.execute_input":"2021-12-11T20:47:36.522979Z","iopub.status.idle":"2021-12-11T20:47:36.529273Z","shell.execute_reply.started":"2021-12-11T20:47:36.522948Z","shell.execute_reply":"2021-12-11T20:47:36.528323Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"Given these plots, it might suggest that the COTS tend to grow near to each other? To brainstorm, this could mean a sequential model would be useful for this problem. That way, once we know we have seen 1 COTS in a video, we can then somehow perhaps \"alert\" the model, to increase the probability of detecting more COTS nearby.","metadata":{}},{"cell_type":"markdown","source":"**Question 2:** What are some \"giveaways\" that a certain object in an video frame is that of a COTS?\n\n- *Part 1:* What is the distibution of the observed colors of COTS in the videos?","metadata":{"id":"a29qvuhOh-5A"}},{"cell_type":"code","source":"pass","metadata":{"id":"_0yCuOIyi1L_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- *Part 2:* What is the distibution of the observed sizes of COTS in the videos?","metadata":{"id":"pc4Nmd6ei1pw"}},{"cell_type":"code","source":"pass","metadata":{"id":"7oy5aiL1i4PH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling\n\nStep 1: Colab-specific: Mount Google Drive (we can do this by clicking the appropiate icons on the screen, please see here for more info)","metadata":{"id":"9D4YhwbDceiK"}},{"cell_type":"code","source":"try:\n  from google.colab import drive\n  drive.mount('/content/drive')\nexcept ModuleNotFoundError:\n  pass","metadata":{"id":"8ie-ZPMMfmK6","outputId":"87219983-b5b8-430e-9e7a-6cb9023e3be6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Colab-specific - find a folder to store YOLOv5 stuff\n%cd ./drive/MyDrive","metadata":{"id":"Rn4HYy82cQEq","outputId":"a8b4336c-f971-456f-da42-ec7527581897"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 2:** Now let's load the YOLOv5 model from the PyTorch Hub:","metadata":{"id":"U7Jxmx77pST0"}},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone\n%cd yolov5\n%pip install -qr requirements.txt  # install","metadata":{"id":"_ElWlt5Vofxl","outputId":"ce560c94-6b08-4a41-ccbd-08657a34cfbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"id":"EYVbFjR8f9Q5","outputId":"f113fb3e-e21f-4da4-8966-08279040c827"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import utils\ndisplay = utils.notebook_init()  # running the checks","metadata":{"id":"Ux8otJbFsE4d","outputId":"0c05a743-77a8-4fab-d02f-9223a3c4827a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 3:** Now, let export to a `SavedModel` (this is using the \"nano\" version of YOLOv5, the smallest). Note that only need to do this *once*:","metadata":{"id":"OGbp452cpp1C"}},{"cell_type":"code","source":"!python export.py --weights yolov5n.pt --include saved_model","metadata":{"id":"FM_p2nh2ptm2","outputId":"c7103709-d637-4086-f0e6-28f4f329ab42"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 4:** Now, let's test loading the model back in via Tensorflow 2:","metadata":{"id":"h1TK9CS0tWZZ"}},{"cell_type":"code","source":"tf_model = tf.keras.models.load_model('./yolov5n_saved_model')","metadata":{"id":"5CNlkCvPsfrp","outputId":"37e6a138-5052-404f-98f2-8d24ac586db7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Woohoo! We got a warning that the model has no training configuration, but that is to be expected (since we want to do all the training code henceforth ourselves, using Tensorflow code). \n\nLet's get started!","metadata":{"id":"gm9_kzUBuINz"}},{"cell_type":"code","source":"","metadata":{"id":"3zARnYg9keEb"},"execution_count":null,"outputs":[]}]}